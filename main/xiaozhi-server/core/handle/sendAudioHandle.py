import json
import time
import asyncio
from core.utils import textUtils
from core.utils.util import audio_to_data
from core.providers.tts.dto.dto import (
    SentenceType,
    MessageTag,
)
from core.utils.textUtils import strip_emotion_tags, get_emotion_tag
from core.utils.opus import pack_opus_with_header
from config.logger import setup_logging

TAG = __name__
logger = setup_logging()

async def sendAudioMessage(conn, sentenceType, audios, text, message_tag=MessageTag.NORMAL):
    # è¯¦ç»†æ—¥å¿—è¿½è¸ª
    audio_len = len(audios) if audios else 0
    
    # åœ¨æ–°å¥å­å¼€å§‹æˆ–ä¼šè¯ç»“æŸå‰ï¼Œå…ˆå‘é€å‰ä¸€ä¸ªå¥å­çš„ sentence_end
    # è¿™ç¡®ä¿ sentence_end åœ¨è¯¥å¥å­çš„æ‰€æœ‰éŸ³é¢‘å‘é€å®Œæ¯•åæ‰å‘é€
    if sentenceType in (SentenceType.FIRST, SentenceType.LAST):
        if hasattr(conn, '_pending_sentence_text') and conn._pending_sentence_text:
            await send_tts_message(conn, "sentence_end", conn._pending_sentence_text, message_tag)
            conn._pending_sentence_text = None

    # IMPORTANT: streaming TTS ä¼šå…ˆå‘ FIRST(ä»…æ–‡æœ¬, audio_data=None) å†äº§å‡ºéŸ³é¢‘(MIDDLE)ã€‚
    # å¦‚æœåœ¨ FIRST(æ— éŸ³é¢‘) æ—¶å°±å‘é€ tts/startï¼Œè®¾å¤‡ç«¯ä¼šè¿›å…¥â€œç­‰å¾…éŸ³é¢‘â€çŠ¶æ€ï¼Œ
    # ä¸€æ—¦é¦–åŒ…éŸ³é¢‘å› ç½‘ç»œ/TTSé¦–åŒ…å»¶è¿Ÿè€Œè¶…è¿‡è®¾å¤‡é˜ˆå€¼ï¼Œå°±ä¼šå…³é—­æ’­æ”¾é€šé“ â†’ ç”¨æˆ·æ— å£°ï¼ˆå¿…ç°/å¶ç°å–å†³äºé˜ˆå€¼ä¸æŠ–åŠ¨ï¼‰ã€‚
    # å› æ­¤ï¼šFIRST(æ— éŸ³é¢‘) åªç¼“å­˜ sentence_start æ–‡æœ¬ï¼Œç­‰åˆ°â€œé¦–ä¸ªéç©ºéŸ³é¢‘åŒ…â€åˆ°æ¥æ—¶å†å‘é€ tts/start + sentence_start + éŸ³é¢‘ã€‚
    has_audio = bool(audios)
    if sentenceType == SentenceType.FIRST and not has_audio:
        if text:
            # è®°å½•å¾…å‘é€çš„ sentence_startï¼ˆç­‰é¦–éŸ³é¢‘åˆ°æ¥æ—¶å†å‘ï¼Œç¡®ä¿ startâ†’audio é—´éš™æå°ï¼‰
            conn._tts_pending_sentence_start_text = text
            conn._tts_pending_sentence_start_message_tag = message_tag
            # è®°å½•å¾…å‘é€çš„ sentence_endï¼ˆä¸‹ä¸€å¥å¼€å§‹/ä¼šè¯ç»“æŸæ—¶å‘é€ï¼‰
            conn._pending_sentence_text = text
        return

    async def _ensure_tts_session_started_before_audio(_log_text: str | None):
        """ç¡®ä¿åœ¨å‘é€ä»»ä½•éŸ³é¢‘å‰ï¼Œtts/start å·²å‘é€ä¸”è®¾å¤‡å·²å®ŒæˆçŠ¶æ€åˆ‡æ¢ã€‚"""
        # åªæœ‰å½“ client_is_speaking ä¸º False æ—¶æ‰å‘é€ tts/start
        # å¦‚æœ wakeup/å…¶ä»–è·¯å¾„å·²å‘é€è¿‡ tts/startï¼Œæ­¤æ—¶ client_is_speaking å·²ä¸º True
        if not conn.client_is_speaking:
            await send_tts_message(conn, "start", None, message_tag)
            conn.client_is_speaking = True

            # ç­‰å¾…è®¾å¤‡ç«¯å®ŒæˆçŠ¶æ€åˆ‡æ¢ï¼ˆSchedule å¼‚æ­¥åˆ‡æ¢ï¼‰
            # ç¡¬ä»¶çº¦æŸï¼šè®¾å¤‡ç«¯éœ€è¦ ~134ms å®Œæˆ Schedule callback + AudioService æ“ä½œ
            # 150ms æ˜¯ç»è¿‡éªŒè¯çš„å®‰å…¨å€¼ï¼Œä¸å¯éšæ„é™ä½
            tts_start_delay = conn.config.get("tts_start_delay_ms", 150) / 1000.0
            # é˜²å¾¡æ€§ç¼–ç¨‹ï¼šè´Ÿå€¼ clamp åˆ° 0
            if tts_start_delay < 0:
                tts_start_delay = 0
            if tts_start_delay > 0:
                conn.logger.bind(tag=TAG).debug(f"â³ ç­‰å¾…è®¾å¤‡çŠ¶æ€åˆ‡æ¢: {tts_start_delay*1000:.0f}ms")
                await asyncio.sleep(tts_start_delay)

        # ä»…åœ¨â€œé¦–ä¸ªéŸ³é¢‘åŒ…â€åˆ°æ¥æ—¶åšä¸€æ¬¡ä¼šè¯çº§æµæ§é‡ç½®ä¸å»¶è¿Ÿæ‰“ç‚¹
        if hasattr(conn, "tts") and getattr(conn.tts, "tts_audio_first_sentence", False):
            conn.tts.tts_audio_first_sentence = False

            # åœ¨æ•´ä¸ª TTS ä¼šè¯å¼€å§‹æ—¶é‡ç½®æµæ§ï¼ˆè€Œä¸æ˜¯æ¯ä¸ªå¥å­å¼€å§‹æ—¶ï¼‰
            if hasattr(conn, "audio_flow_control"):
                conn.audio_flow_control["start_time"] = time.perf_counter()
                conn.audio_flow_control["packet_count"] = 0
                conn.audio_flow_control["last_send_time"] = 0
                conn.logger.bind(tag=TAG).debug("é‡ç½®éŸ³é¢‘æµæ§çŠ¶æ€ (TTSä¼šè¯å¼€å§‹)")

            # è®°å½•é¦–å¥ TTS æ’­æ”¾æ—¶é—´ï¼ˆç«¯åˆ°ç«¯å»¶è¿Ÿçš„ç»ˆç‚¹ï¼‰
            first_audio_time = time.time() * 1000

            # è®¡ç®— TTS é¦–åŒ…å»¶è¿Ÿï¼ˆè¾“å…¥åˆ°è¾“å‡ºï¼‰
            tts_first_package_delay = 0
            if hasattr(conn, "_latency_tts_first_text_time") and conn._latency_tts_first_text_time:
                tts_first_package_delay = first_audio_time - conn._latency_tts_first_text_time

            # è®¡ç®—ç«¯åˆ°ç«¯å»¶è¿Ÿ
            e2e_total_delay = 0
            if hasattr(conn, "_latency_voice_end_time"):
                e2e_total_delay = first_audio_time - conn._latency_voice_end_time

            conn.logger.bind(tag=TAG).info(
                f"ğŸ”Š [å»¶è¿Ÿè¿½è¸ª] é¦–å¥TTSå¼€å§‹æ’­æ”¾ | "
                f"TTSé¦–åŒ…å»¶è¿Ÿ: {tts_first_package_delay:.0f}ms | "
                f"â±ï¸  ç«¯åˆ°ç«¯æ€»å»¶è¿Ÿ: {e2e_total_delay:.0f}ms (ç”¨æˆ·è¯´å®Œâ†’é¦–å¥æ’­æ”¾) | "
                f"æ–‡æœ¬: {_log_text if _log_text else '(æ— æ–‡æœ¬)'}"
            )
    
    if sentenceType == SentenceType.FIRST:
        # FIRST ä¸”æœ‰éŸ³é¢‘ï¼šåœ¨å‘é€éŸ³é¢‘å‰ç¡®ä¿ä¼šè¯å·²å¯åŠ¨ï¼ˆstartâ†’audio é—´éš™ä»…å‰© tts_start_delay_msï¼‰
        await _ensure_tts_session_started_before_audio(text)
        await send_tts_message(conn, "sentence_start", text, message_tag)
        # ä¿å­˜å½“å‰å¥å­çš„æ–‡æœ¬ï¼Œç­‰å¾…è¯¥å¥å­çš„éŸ³é¢‘å‘é€å®Œæ¯•åå†å‘é€ sentence_end
        conn._pending_sentence_text = text if text else None
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„â€œå»¶è¿Ÿå‘é€ sentence_startâ€ç¼“å­˜
        if hasattr(conn, "_tts_pending_sentence_start_text"):
            conn._tts_pending_sentence_start_text = None
        if hasattr(conn, "_tts_pending_sentence_start_message_tag"):
            conn._tts_pending_sentence_start_message_tag = None

    # MIDDLE(éŸ³é¢‘) ä¸”å­˜åœ¨å¾…å‘é€ sentence_startï¼šå…ˆè¡¥å‘ sentence_startï¼Œå†ä¸‹å‘éŸ³é¢‘
    if sentenceType == SentenceType.MIDDLE and has_audio:
        pending_start_text = getattr(conn, "_tts_pending_sentence_start_text", None)
        if pending_start_text:
            pending_tag = getattr(conn, "_tts_pending_sentence_start_message_tag", message_tag)
            # ç¡®ä¿ tts/start åœ¨ sentence_start ä¹‹å‰
            await _ensure_tts_session_started_before_audio(pending_start_text)
            await send_tts_message(conn, "sentence_start", pending_start_text, pending_tag)
            # ä¿å­˜å½“å‰å¥å­çš„æ–‡æœ¬ï¼Œç­‰å¾…è¯¥å¥å­çš„éŸ³é¢‘å‘é€å®Œæ¯•åå†å‘é€ sentence_end
            conn._pending_sentence_text = pending_start_text
            conn._tts_pending_sentence_start_text = None
            conn._tts_pending_sentence_start_message_tag = None
        else:
            # æ²¡æœ‰ sentence_start æ–‡æœ¬ï¼ˆå¼‚å¸¸/å…¼å®¹åœºæ™¯ï¼‰ï¼Œä½†ä»éœ€ç¡®ä¿ start åœ¨é¦–éŸ³é¢‘å‰
            if not conn.client_is_speaking:
                await _ensure_tts_session_started_before_audio(None)

    await sendAudio(conn, audios, message_tag=message_tag)
    
    # å‘é€å¥å­å¼€å§‹æ¶ˆæ¯
    if sentenceType is not SentenceType.MIDDLE:
        conn.logger.bind(tag=TAG).info(f"å‘é€éŸ³é¢‘æ¶ˆæ¯: {sentenceType}, {text}")

    # å‘é€ç»“æŸæ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯æœ€åä¸€ä¸ªæ–‡æœ¬ï¼‰
    if sentenceType == SentenceType.LAST:
        await send_tts_message(conn, "stop", None, message_tag)
        conn.client_is_speaking = False
        if conn.close_after_chat:
            await conn.close()


def calculate_timestamp_and_sequence(conn, start_time, packet_index, frame_duration=60):
    """
    è®¡ç®—éŸ³é¢‘æ•°æ®åŒ…çš„æ—¶é—´æˆ³å’Œåºåˆ—å·
    Args:
        conn: è¿æ¥å¯¹è±¡
        start_time: èµ·å§‹æ—¶é—´ï¼ˆæ€§èƒ½è®¡æ•°å™¨å€¼ï¼‰
        packet_index: æ•°æ®åŒ…ç´¢å¼•
        frame_duration: å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼ŒåŒ¹é… Opus ç¼–ç 
    Returns:
        tuple: (timestamp, sequence)
    """
    # è®¡ç®—æ—¶é—´æˆ³ï¼ˆä½¿ç”¨æ’­æ”¾ä½ç½®è®¡ç®—ï¼‰
    timestamp = int((start_time + packet_index * frame_duration / 1000) * 1000) % (
        2**32
    )

    # è®¡ç®—åºåˆ—å·
    if hasattr(conn, "audio_flow_control"):
        sequence = conn.audio_flow_control["sequence"]
    else:
        sequence = packet_index  # å¦‚æœæ²¡æœ‰æµæ§çŠ¶æ€ï¼Œç›´æ¥ä½¿ç”¨ç´¢å¼•

    return timestamp, sequence


async def _send_to_mqtt_gateway(conn, opus_packet, timestamp, sequence):
    """
    å‘é€å¸¦16å­—èŠ‚å¤´éƒ¨çš„opusæ•°æ®åŒ…ç»™mqtt_gateway
    Args:
        conn: è¿æ¥å¯¹è±¡
        opus_packet: opusæ•°æ®åŒ…
        timestamp: æ—¶é—´æˆ³
        sequence: åºåˆ—å·
    """
    # ä¸ºopusæ•°æ®åŒ…æ·»åŠ 16å­—èŠ‚å¤´éƒ¨
    header = bytearray(16)
    header[0] = 1  # type
    header[2:4] = len(opus_packet).to_bytes(2, "big")  # payload length
    header[4:8] = sequence.to_bytes(4, "big")  # sequence
    header[8:12] = timestamp.to_bytes(4, "big")  # æ—¶é—´æˆ³
    header[12:16] = len(opus_packet).to_bytes(4, "big")  # opusé•¿åº¦

    # å‘é€åŒ…å«å¤´éƒ¨çš„å®Œæ•´æ•°æ®åŒ…
    complete_packet = bytes(header) + opus_packet
    await conn.websocket.send(complete_packet)

async def _send_audio_with_header(conn, audios, message_tag=MessageTag.NORMAL):
    if audios is None or len(audios) == 0:
        return
    # ç»Ÿä¸€å‘é€å¸¦ 16 å­—èŠ‚å¤´éƒ¨çš„éŸ³é¢‘åŒ…
    # éå®˜æ–¹æœåŠ¡å™¨çš„è®¾å¤‡ç«¯ï¼ˆis_official_server_=falseï¼‰æœŸæœ›å¸¦å¤´éƒ¨çš„æ•°æ®
    # å¤´éƒ¨æ ¼å¼ï¼štype(1) + message_tag(1) + payload_size(4, big-endian) + reserved(10) = 16 bytes
    complete_packet = pack_opus_with_header(audios, message_tag)
    # conn.logger.bind(tag=TAG).debug(f"ğŸ“¤ å‘é€éŸ³é¢‘åŒ…: {len(complete_packet)} bytes (opus={len(audios)}, with header)")
    await conn.websocket.send(complete_packet)
    # ç¡®ä¿æ•°æ®ç«‹å³å‘é€åˆ°ç½‘ç»œï¼ˆé¿å… asyncio è°ƒåº¦å»¶è¿Ÿå¯¼è‡´ç¼“å†²åŒºç§¯å‹ï¼‰
    # websockets åº“çš„ send() å†…éƒ¨ä¼šç­‰å¾… drainï¼Œä½†åœ¨é«˜é¢‘å‘é€æ—¶å¯èƒ½éœ€è¦æ˜¾å¼è®©å‡ºæ§åˆ¶æƒ
    # ä½¿ç”¨ sleep(0) è®©äº‹ä»¶å¾ªç¯æœ‰æœºä¼šå¤„ç† I/O
    await asyncio.sleep(0)


# æ’­æ”¾éŸ³é¢‘
async def sendAudio(conn, audios, frame_duration=60, message_tag=MessageTag.NORMAL):
    """
    å‘é€å•ä¸ªopusåŒ…ï¼Œæ”¯æŒæµæ§
    Args:
        conn: è¿æ¥å¯¹è±¡
        opus_packet: å•ä¸ªopusæ•°æ®åŒ…
        pre_buffer: å¿«é€Ÿå‘é€éŸ³é¢‘
        frame_duration: å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼ŒåŒ¹é… Opus ç¼–ç 
    """
    if audios is None or len(audios) == 0:
        return

    # è·å–å‘é€å»¶è¿Ÿé…ç½®
    send_delay = conn.config.get("tts_audio_send_delay", -1) / 1000.0

    if isinstance(audios, bytes):
        if conn.client_abort:
            conn.logger.bind(tag=TAG).debug(f"âš ï¸ client_abort=True, è·³è¿‡éŸ³é¢‘å‘é€")
            return

        conn.last_activity_time = time.time() * 1000

        # è·å–æˆ–åˆå§‹åŒ–æµæ§çŠ¶æ€
        if not hasattr(conn, "audio_flow_control"):
            conn.audio_flow_control = {
                "last_send_time": 0,
                "packet_count": 0,
                "start_time": time.perf_counter(),
                "sequence": 0,  # æ·»åŠ åºåˆ—å·
            }

        flow_control = conn.audio_flow_control
        current_time = time.perf_counter()
        
        # æ¯ 20 ä¸ªåŒ…è®°å½•ä¸€æ¬¡æµæ§çŠ¶æ€
        if flow_control["packet_count"] % 20 == 0:
            conn.logger.bind(tag=TAG).debug(
                f"ğŸ“Š æµæ§çŠ¶æ€: packet_count={flow_control['packet_count']}, "
                f"elapsed={current_time - flow_control['start_time']:.2f}s"
            )
        
        # æµæ§é…ç½®
        pre_buffer_count = conn.config.get("tts_audio_pre_buffer_count", 8)  # é¢„ç¼“å†²åŒ…æ•°ï¼ˆçº¦480msï¼‰
        speed_multiplier = conn.config.get("tts_audio_speed_multiplier", 1.0)  # å‘é€é€Ÿåº¦å€ç‡
        
        # æœ€å°å‘é€é—´éš”ï¼ˆæ¯«ç§’ï¼‰- é¿å…æ•°æ®çªå‘å¯¼è‡´è®¾å¤‡ç«¯ç¼“å†²åŒºæº¢å‡º
        min_send_interval_ms = conn.config.get("tts_audio_min_send_interval_ms", 5)
        
        if send_delay > 0:
            # ä½¿ç”¨å›ºå®šå»¶è¿Ÿ
            await asyncio.sleep(send_delay)
        elif flow_control["packet_count"] < pre_buffer_count:
            # é¢„ç¼“å†²é˜¶æ®µï¼šå¿«é€Ÿå‘é€ï¼Œä½†ä»éœ€è¦æœ€å°é—´éš”é¿å…çªå‘
            if min_send_interval_ms > 0 and flow_control["packet_count"] > 0:
                await asyncio.sleep(min_send_interval_ms / 1000.0)
        else:
            # æŒ‰ç•¥å¿«äºå®æ—¶çš„é€Ÿåº¦å‘é€
            packets_after_prebuffer = flow_control["packet_count"] - pre_buffer_count
            expected_time = flow_control["start_time"] + (
                packets_after_prebuffer * frame_duration / 1000 / speed_multiplier
            )
            delay = expected_time - current_time
            if delay > 0:
                await asyncio.sleep(delay)
            else:
                # çº æ­£è¯¯å·®
                flow_control["start_time"] += abs(delay)

        if conn.conn_from_mqtt_gateway:
            # è®¡ç®—æ—¶é—´æˆ³å’Œåºåˆ—å·
            timestamp, sequence = calculate_timestamp_and_sequence(
                conn,
                flow_control["start_time"],
                flow_control["packet_count"],
                frame_duration,
            )
            # è°ƒç”¨é€šç”¨å‡½æ•°å‘é€å¸¦å¤´éƒ¨çš„æ•°æ®åŒ…
            await _send_to_mqtt_gateway(conn, audios, timestamp, sequence)
        else:
            # ç›´æ¥å‘é€opusæ•°æ®åŒ…ï¼Œä¸æ·»åŠ å¤´éƒ¨
            await _send_audio_with_header(conn, audios, message_tag)

        # æ›´æ–°æµæ§çŠ¶æ€
        flow_control["packet_count"] += 1
        flow_control["sequence"] += 1
        flow_control["last_send_time"] = time.perf_counter()
    else:
        # æ–‡ä»¶å‹éŸ³é¢‘èµ°æ™®é€šæ’­æ”¾
        start_time = time.perf_counter()
        play_position = 0

        # æ‰§è¡Œé¢„ç¼“å†²
        pre_buffer_frames = min(3, len(audios))
        for i in range(pre_buffer_frames):
            if conn.conn_from_mqtt_gateway:
                # è®¡ç®—æ—¶é—´æˆ³å’Œåºåˆ—å·
                timestamp, sequence = calculate_timestamp_and_sequence(
                    conn, start_time, i, frame_duration
                )
                # è°ƒç”¨é€šç”¨å‡½æ•°å‘é€å¸¦å¤´éƒ¨çš„æ•°æ®åŒ…
                await _send_to_mqtt_gateway(conn, audios[i], timestamp, sequence)
            else:
                # ç›´æ¥å‘é€é¢„ç¼“å†²åŒ…ï¼Œä¸æ·»åŠ å¤´éƒ¨
                await _send_audio_with_header(conn, audios[i], message_tag)
        remaining_audios = audios[pre_buffer_frames:]

        # æ’­æ”¾å‰©ä½™éŸ³é¢‘å¸§
        for i, opus_packet in enumerate(remaining_audios):
            if conn.client_abort:
                break

            # é‡ç½®æ²¡æœ‰å£°éŸ³çš„çŠ¶æ€
            conn.last_activity_time = time.time() * 1000

            if send_delay > 0:
                # å›ºå®šå»¶è¿Ÿæ¨¡å¼
                await asyncio.sleep(send_delay)
            else:
                 # è®¡ç®—é¢„æœŸå‘é€æ—¶é—´
                expected_time = start_time + (play_position / 1000)
                current_time = time.perf_counter()
                delay = expected_time - current_time
                if delay > 0:
                    await asyncio.sleep(delay)

            if conn.conn_from_mqtt_gateway:
                # è®¡ç®—æ—¶é—´æˆ³å’Œåºåˆ—å·ï¼ˆä½¿ç”¨å½“å‰çš„æ•°æ®åŒ…ç´¢å¼•ç¡®ä¿è¿ç»­æ€§ï¼‰
                packet_index = pre_buffer_frames + i
                timestamp, sequence = calculate_timestamp_and_sequence(
                    conn, start_time, packet_index, frame_duration
                )
                # è°ƒç”¨é€šç”¨å‡½æ•°å‘é€å¸¦å¤´éƒ¨çš„æ•°æ®åŒ…
                await _send_to_mqtt_gateway(conn, opus_packet, timestamp, sequence)
            else:
                # ç›´æ¥å‘é€opusæ•°æ®åŒ…ï¼Œä¸æ·»åŠ å¤´éƒ¨
                await _send_audio_with_header(conn, opus_packet, message_tag)

            play_position += frame_duration


async def send_tts_message(conn, state, text=None, message_tag=MessageTag.NORMAL):
    """å‘é€ TTS çŠ¶æ€æ¶ˆæ¯
    
    Args:
        conn: Connection object
        state: TTS state (start, sentence_start, stop)
        text: Optional text content
        message_tag: Message tag for categorization
    """
    if text is None and state == "sentence_start":
        return
    
    message = {
        "type": "tts", 
        "state": state,
        "session_id": conn.session_id,
        "message_tag": message_tag.value,
    }
    
    # TTS å¼€å§‹æ—¶æ·»åŠ  sample_rate å‚æ•°ï¼ˆå®˜æ–¹åè®®è¦æ±‚ï¼‰
    if state == "start":
        # ä»é…ç½®ä¸­è·å– TTS çš„ sample_rateï¼Œé»˜è®¤ 16000
        tts_sample_rate = conn.config.get("xiaozhi", {}).get("audio_params", {}).get("sample_rate", 16000)
        message["sample_rate"] = tts_sample_rate
    
    if text is not None:
        text = textUtils.check_emoji(text)
        # Extract emotion tag before stripping
        emotion = get_emotion_tag(text)
        if emotion:
            message["emotion"] = emotion
        text = strip_emotion_tags(text)
        message["text"] = text

    # TTSæ’­æ”¾ç»“æŸ
    if state == "stop":
        # é¦–è½®å¯¹è¯å®Œæˆï¼Œå¯ç”¨æ‰“æ–­æ£€æµ‹
        if not getattr(conn, "first_dialogue_completed", False):
            conn.first_dialogue_completed = True
            logger.bind(tag=TAG).info("é¦–è½®å¯¹è¯å®Œæˆï¼Œå¯ç”¨æ‰“æ–­æ£€æµ‹")
        # æ’­æ”¾æç¤ºéŸ³
        tts_notify = conn.config.get("enable_stop_tts_notify", False)
        if tts_notify:
            stop_tts_notify_voice = conn.config.get(
                "stop_tts_notify_voice", "config/assets/tts_notify.mp3"
            )
            audios = audio_to_data(stop_tts_notify_voice, is_opus=True)
            await sendAudio(conn, audios)
        # æ¸…é™¤æœåŠ¡ç«¯è®²è¯çŠ¶æ€
        conn.clearSpeakStatus()

    # å‘é€æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯
    logger.bind(tag=TAG).info(f"å‘é€TTSæ¶ˆæ¯: {message}")
    await conn.websocket.send(json.dumps(message))
    # ç¡®ä¿æ¶ˆæ¯ç«‹å³å‘é€åˆ°ç½‘ç»œï¼ˆé¿å… TCP ç¼“å†²åŒºç§¯å‹ï¼‰
    await asyncio.sleep(0)


async def send_stt_message(conn, text):
    """å‘é€ STT çŠ¶æ€æ¶ˆæ¯ï¼ˆä»…å‘é€ç”¨æˆ·è¯†åˆ«æ–‡æœ¬ï¼Œä¸å¯åŠ¨ TTS ä¼šè¯ï¼‰
    
    ä¿®å¤è¯´æ˜ï¼ˆ2025-12-27ï¼‰:
    ä¹‹å‰æ­¤å‡½æ•°ä¼šæå‰å‘é€ tts start æ¥"é¢„çƒ­"è®¾å¤‡ï¼Œä½†è¿™å¯¼è‡´äº†é—®é¢˜ï¼š
    - tts start å‘é€åï¼Œè®¾å¤‡è¿›å…¥ç­‰å¾…éŸ³é¢‘çŠ¶æ€
    - LLM ç”Ÿæˆ + TTS åˆæˆéœ€è¦ 1-2 ç§’
    - è®¾å¤‡ç­‰å¾…è¶…æ—¶ï¼ˆé€šå¸¸ 1-2 ç§’é˜ˆå€¼ï¼‰ï¼Œå…³é—­æ’­æ”¾é€šé“
    - åç»­éŸ³é¢‘åˆ°è¾¾æ—¶è¢«ä¸¢å¼ƒï¼Œç”¨æˆ·å¬ä¸åˆ°å›å¤
    
    ä¿®å¤æ–¹æ¡ˆï¼š
    - æ­¤å‡½æ•°åªå‘é€ STT æ–‡æœ¬æ¶ˆæ¯ï¼ˆç”¨äº UI æ˜¾ç¤ºç”¨æˆ·è¯´äº†ä»€ä¹ˆï¼‰
    - tts start ç”± sendAudioMessage åœ¨é¦–å¸§éŸ³é¢‘å‡†å¤‡å¥½æ—¶å‘é€
    - ç¡®ä¿ tts start ä¸éŸ³é¢‘æ•°æ®ç´§å¯†è¡”æ¥ï¼Œæ¶ˆé™¤è¶…æ—¶é—´éš™
    
    æ³¨æ„ï¼šæ­¤å‡½æ•°åœ¨åŒä¸€å¯¹è¯è½®æ¬¡ä¸­åªåº”è¢«è°ƒç”¨ä¸€æ¬¡ã€‚
    å¦‚æœ client_is_speaking å·²ä¸º Trueï¼Œè¯´æ˜æœ¬è½®å¯¹è¯å·²å¼€å§‹ï¼Œ
    æ­¤æ—¶å†æ¬¡è°ƒç”¨æ˜¯é‡å¤çš„ï¼ˆå¯èƒ½ç”±äº wake word éŸ³é¢‘è¢«è¯¯è¯†åˆ«å¯¼è‡´ï¼‰ã€‚
    """
    # é˜²æ­¢é‡å¤å‘é€ï¼šå¦‚æœå·²ç»åœ¨ speaking çŠ¶æ€ï¼Œè¯´æ˜æœ¬è½®å¯¹è¯çš„ stt å·²ç»å‘é€è¿‡äº†
    if conn.client_is_speaking:
        logger.bind(tag=TAG).warning(
            f"è·³è¿‡é‡å¤çš„ stt æ¶ˆæ¯å‘é€ï¼šå·²åœ¨ speaking çŠ¶æ€ (text: {text[:50] if text else ''}...)"
        )
        return
    
    # end_prompt æ˜¯ç‰¹æ®Šåœºæ™¯ï¼šç”¨æˆ·è¯´"å†è§"ç­‰ç»“æŸè¯­æ—¶ï¼Œåªéœ€å¯åŠ¨ TTS æ’­æ”¾å‘Šåˆ«è¯­
    end_prompt_str = conn.config.get("end_prompt", {}).get("prompt")
    if end_prompt_str and end_prompt_str == text:
        await send_tts_message(conn, "start")
        return

    # è§£æJSONæ ¼å¼ï¼Œæå–å®é™…çš„ç”¨æˆ·è¯´è¯å†…å®¹
    display_text = text
    try:
        # å°è¯•è§£æJSONæ ¼å¼
        if text.strip().startswith("{") and text.strip().endswith("}"):
            parsed_data = json.loads(text)
            if isinstance(parsed_data, dict) and "content" in parsed_data:
                # å¦‚æœæ˜¯åŒ…å«è¯´è¯äººä¿¡æ¯çš„JSONæ ¼å¼ï¼Œåªæ˜¾ç¤ºcontentéƒ¨åˆ†
                display_text = parsed_data["content"]
                # ä¿å­˜è¯´è¯äººä¿¡æ¯åˆ°connå¯¹è±¡
                if "speaker" in parsed_data:
                    conn.current_speaker = parsed_data["speaker"]
    except (json.JSONDecodeError, TypeError):
        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬
        display_text = text
    stt_text = textUtils.get_string_no_punctuation_or_emoji(display_text)
    
    # åªå‘é€ STT æ–‡æœ¬æ¶ˆæ¯ï¼ˆç”¨äºè®¾å¤‡ç«¯ UI æ˜¾ç¤ºç”¨æˆ·è¯´äº†ä»€ä¹ˆï¼‰
    # ä¸å†å‘é€ tts startï¼Œä¹Ÿä¸è®¾ç½® client_is_speaking
    # tts start å°†ç”± sendAudioMessage åœ¨é¦–å¸§éŸ³é¢‘åˆ°è¾¾æ—¶å‘é€
    await conn.websocket.send(
        json.dumps({"type": "stt", "text": stt_text, "session_id": conn.session_id})
    )
    # ç¡®ä¿æ¶ˆæ¯ç«‹å³å‘é€åˆ°ç½‘ç»œ
    await asyncio.sleep(0)
    logger.bind(tag=TAG).info(f"å‘é€STTæ¶ˆæ¯: {stt_text}")
