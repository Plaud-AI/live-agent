import queue
import asyncio
import traceback
import time
import httpx
import threading
from concurrent.futures import ThreadPoolExecutor
from config.logger import setup_logging
from core.utils.tts import MarkdownCleaner
from core.providers.tts.base import TTSProviderBase
from core.utils import opus_encoder_utils, textUtils
from core.providers.tts.dto.dto import SentenceType, ContentType, InterfaceType, TTSAudioDTO, MessageTag
from fishaudio import FishAudio, TTSConfig

TAG = __name__
logger = setup_logging()


class TTSProvider(TTSProviderBase):
    
    # Text segmentation punctuation sets
    #
    # HARD_PUNCTS: sentence-ending punctuation (safer boundaries)
    # SOFT_PUNCTS: clause boundaries (lower latency, may cut mid-sentence)
    #
    # Note:
    # - Include '.' for English sentences, but we skip decimal points like "1.5"
    # - Also include fullwidth dot 'ï¼Ž' (U+FF0E) which may appear in some model outputs
    HARD_PUNCTS = (".", "ã€‚", "ï¼", "ï¼Ÿ", "!", "?", "ï¼›", ";", "ï¼Ž")
    SOFT_PUNCTS = (",", "ï¼Œ", "ï¼š", ":", "\n")
    # First segment: allow both soft + hard for faster first audio
    FIRST_SEGMENT_PUNCTS = SOFT_PUNCTS + HARD_PUNCTS
    # Normal segments: prefer hard; optionally allow soft when segment is long enough
    NORMAL_PUNCTS = HARD_PUNCTS

    def __init__(self, config, delete_audio_file):
        super().__init__(config, delete_audio_file)
        
        # Mark as streaming interface
        self.interface_type = InterfaceType.SINGLE_STREAM

        # Fish Audio configuration
        self.api_key = config.get("api_key")
        if not self.api_key:
            raise ValueError("FishSpeech API key is required")
        
        # Create httpx client with connection pool for reuse
        self._httpx_client = httpx.Client(
            base_url="https://api.fish.audio",  # Required for path-only requests
            limits=httpx.Limits(max_connections=10, max_keepalive_connections=5),
            timeout=httpx.Timeout(60.0),
            http2=True,  # Enable HTTP/2 for better multiplexing
        )
        self._client = FishAudio(api_key=self.api_key, httpx_client=self._httpx_client)
        
        self.model = config.get("model", "speech-1.6")
        self.reference_id = config.get("reference_id")
        self.format = config.get("response_format", "pcm")
        # IMPORTANT: base-class to_tts()/to_tts_stream() uses audio_file_type to decide how to decode bytes.
        # FishAudio returns bytes in `response_format` (default pcm). If we keep base default "wav",
        # PCM would be treated as WAV and ffmpeg will fail with "invalid RIFF header".
        self.audio_file_type = self.format
        self.sample_rate = int(config.get("sample_rate", 16000))
        self.normalize = str(config.get("normalize", True)).lower() in ("true", "1", "yes")
        # FishAudio latency mode (keep backward-compatible default)
        self.latency_mode = config.get("latency_mode", "balanced")

        # Segmentation tuning (latency vs naturalness)
        # - max chars: hard cap to prevent pathological long segments (reduces TTS first-chunk spikes)
        # - soft punct min chars: avoid over-fragmentation at early commas
        #
        # ä¼˜åŒ–è¯´æ˜Ž (2024-12-30):
        # - first_soft_punct_min_chars: ä»Ž 0 æ”¹ä¸º 12ï¼Œé¿å… "(calm) Ah," ç­‰è¿‡çŸ­é¦–å¥å¯¼è‡´åžå­—
        # - soft_punct_min_chars: ä»Ž 25 æ”¹ä¸º 30ï¼Œå‡å°‘é€—å·å¤„çš„è¿‡åº¦åˆ†å‰²
        # - é—®é¢˜åœºæ™¯ï¼šLLM è¾“å‡º "(calm) Ah, a new presence..." æ—¶
        #   åŽŸé€»è¾‘ä¼šåœ¨ "Ah," å¤„åˆ†å‰²ï¼Œå¯¼è‡´ TTS ç‰‡æ®µè¿‡çŸ­ï¼Œè®¾å¤‡ç«¯æ’­æ”¾æ—¶åžå­—
        self.first_segment_max_chars = int(config.get("first_segment_max_chars", 120))
        self.segment_max_chars = int(config.get("segment_max_chars", 160))
        self.enable_soft_puncts = str(config.get("enable_soft_puncts", True)).lower() in ("true", "1", "yes")
        self.first_soft_punct_min_chars = int(config.get("first_soft_punct_min_chars", 12))  # åŽŸå€¼ 0ï¼Œä¼˜åŒ–ä¸º 12ï¼ˆé˜»æ­¢ "Ah," ç­‰è¿‡çŸ­ç‰‡æ®µï¼‰
        self.soft_punct_min_chars = int(config.get("soft_punct_min_chars", 30))  # åŽŸå€¼ 25ï¼Œä¼˜åŒ–ä¸º 30

        # Prefetch configuration - é¢„åŠ è½½æ·±åº¦ï¼ˆåŒæ—¶è¿›è¡Œçš„ TTS è¯·æ±‚æ•°ï¼‰
        # æ³¨æ„ï¼šFishSpeech API å¯èƒ½æœ‰å¹¶å‘é™åˆ¶ï¼Œå»ºè®®è®¾ä¸º 2 é¿å…é™é€Ÿ
        self.prefetch_depth = int(config.get("prefetch_depth", 2))

        # Initialize Opus encoder
        self.opus_encoder = opus_encoder_utils.OpusEncoderUtils(
            sample_rate=self.sample_rate, channels=1, frame_size_ms=60
        )

        # PCM buffer for accumulating data before encoding
        self.pcm_buffer = bytearray()
        
        # Session state
        self._session_started = False
        
        # Disable base class first sentence handling (STT already sends start)
        self.tts_audio_first_sentence = False
        
        # Text buffer state
        self._text_buffer = ""
        self._processed_idx = 0
        
        # Prefetch state
        self._prefetch_buffers = {}  # segment_idx -> {"text": str, "audio_chunks": [], "done": Event, "error": Exception}
        self._prefetch_lock = threading.Lock()
        self._next_send_idx = 0  # ä»Ž 0 å¼€å§‹ï¼Œæ‰€æœ‰å¥å­éƒ½é€šè¿‡ prefetch æœºåˆ¶å¤„ç†
        self._segment_idx = 0
        self._tts_executor = None
        
        # é¦–å¥æµå¼å‘é€çŠ¶æ€ (segment 0 ä½¿ç”¨æµå¼æ¨¡å¼ï¼Œè¾¹æŽ¥æ”¶è¾¹å‘é€)
        self._first_segment_streaming = False
        self._first_segment_audio_queue = queue.Queue()  # é¦–å¥éŸ³é¢‘é˜Ÿåˆ—
        self._first_segment_done = threading.Event()

    def _get_tts_executor(self):
        """æ‡’åŠ è½½ TTS çº¿ç¨‹æ± """
        if self._tts_executor is None:
            self._tts_executor = ThreadPoolExecutor(
                max_workers=self.prefetch_depth,
                thread_name_prefix="TTS-Prefetch"
            )
        return self._tts_executor

    def tts_text_priority_thread(self):
        """Streaming text processing thread with prefetch pipeline.
        
        Lifecycle alignment:
        - tts_text_queue FIRST -> initialize session
        - tts_text_queue TEXT -> extract segments, prefetch TTS
        - tts_text_queue LAST -> flush remaining, send LAST
        
        Prefetch mechanism:
        - Multiple segments can be processed in parallel
        - Audio is sent in order (segment 0, then 1, then 2...)
        - First segment is streamed directly for low latency
        - Subsequent segments are prefetched while previous ones play
        """
        while not self.conn.stop_event.is_set():
            try:
                # å°è¯•å¤„ç†å·²å®Œæˆçš„é¢„åŠ è½½ä»»åŠ¡ï¼ˆå³ä½¿æ²¡æœ‰æ–°æ¶ˆæ¯ï¼‰
                self._flush_completed_prefetch()
                
                try:
                    message = self.tts_text_queue.get(timeout=0.1)
                except queue.Empty:
                    continue
                
                # Handle FIRST - session start
                if message.sentence_type == SentenceType.FIRST:
                    self.conn.client_abort = False
                    self._text_buffer = ""
                    self._processed_idx = 0
                    self._session_started = False
                    self.pcm_buffer.clear()
                    self.conn._latency_tts_first_text_time = None
                    
                    # è®¾ç½®é¦–å¥æ ‡å¿—ï¼Œç”¨äºŽè§¦å‘ sendAudioHandle ä¸­çš„æµæŽ§é‡ç½®
                    # tts start çš„å‘é€ç”± sendAudioHandle.py ç»Ÿä¸€å¤„ç†
                    self.tts_audio_first_sentence = True
                    
                    # æ¸…ç†é¢„åŠ è½½çŠ¶æ€
                    # çŽ°åœ¨æ‰€æœ‰å¥å­éƒ½é€šè¿‡ prefetch æœºåˆ¶å¤„ç†ï¼Œ_next_send_idx ä»Ž 0 å¼€å§‹
                    with self._prefetch_lock:
                        self._prefetch_buffers.clear()
                        self._next_send_idx = 0  # ä»Ž 0 å¼€å§‹
                        self._segment_idx = 0
                    
                    # æ¸…ç†é¦–å¥æµå¼çŠ¶æ€
                    self._first_segment_streaming = False
                    self._first_segment_done.clear()
                    # æ¸…ç©ºé¦–å¥éŸ³é¢‘é˜Ÿåˆ—
                    while not self._first_segment_audio_queue.empty():
                        try:
                            self._first_segment_audio_queue.get_nowait()
                        except queue.Empty:
                            break
                    
                    logger.bind(tag=TAG).debug("TTS session initialized (prefetch enabled)")
                    continue
                
                # Check for abort
                if self.conn.client_abort:
                    logger.bind(tag=TAG).info("Received abort signal, skipping TTS processing")
                    # If session was started, send LAST to close it
                    if self._session_started:
                        self.tts_audio_queue.put(TTSAudioDTO(
                            sentence_type=SentenceType.LAST,
                            audio_data=None,
                            text=None,
                            message_tag=self._message_tag,
                        ))
                        self._session_started = False
                    # æ¸…ç†é¢„åŠ è½½
                    with self._prefetch_lock:
                        self._prefetch_buffers.clear()
                    continue
                
                # Handle TEXT content
                if ContentType.TEXT == message.content_type:
                    self._text_buffer += message.content_detail
                    
                    # æå–æ‰€æœ‰å¯ç”¨çš„å¥å­
                    while True:
                        segment = self._extract_segment()
                        if not segment:
                            break
                        
                        # Record TTS first text input time (for latency tracking)
                        if self.conn._latency_tts_first_text_time is None:
                            self.conn._latency_tts_first_text_time = time.time() * 1000
                            logger.bind(tag=TAG).debug("ðŸ“ [Latency] TTS received first text")
                        
                        # ã€æ ¸å¿ƒä¼˜åŒ–ã€‘æ‰€æœ‰å¥å­éƒ½ç«‹å³æäº¤åˆ°åŽå°çº¿ç¨‹
                        # é¦–å¥ (segment 0) ä½¿ç”¨æµå¼æ¨¡å¼ï¼ŒåŽç»­å¥å­ä½¿ç”¨ç¼“å†²æ¨¡å¼
                        # è¿™æ ·æ¶ˆæ¯å¤„ç†å¾ªçŽ¯æ°¸ä¸é˜»å¡žï¼ŒåŽç»­å¥å­å¯ä»¥å°½æ—©å¼€å§‹ prefetch
                        self._submit_prefetch_async(segment)
                    
                    # å°è¯•å‘é€å·²å®Œæˆçš„é¢„åŠ è½½
                    self._flush_completed_prefetch()
                    
                    # é¦–å¥æµå¼å‘é€ï¼ˆéžé˜»å¡žï¼Œä»Žé˜Ÿåˆ—è¯»å–å·²æŽ¥æ”¶çš„ chunkï¼‰
                    self._send_first_segment_chunks()
                
                # Handle LAST - session end
                if message.sentence_type == SentenceType.LAST:
                    # Process remaining text
                    remaining = self._text_buffer[self._processed_idx:]
                    if remaining.strip():
                        segment = textUtils.get_string_no_punctuation_or_emoji(remaining)
                        if segment:
                            # ç»Ÿä¸€ä½¿ç”¨éžé˜»å¡žæäº¤
                            self._submit_prefetch_async(segment)
                    
                    # ç­‰å¾…æ‰€æœ‰é¢„åŠ è½½å®Œæˆå¹¶å‘é€
                    self._flush_all_prefetch()
                    
                    # Send LAST to audio queue
                    self.tts_audio_queue.put(TTSAudioDTO(
                        sentence_type=SentenceType.LAST,
                        audio_data=None,
                        text=None,
                        message_tag=self._message_tag,
                    ))
                    
                    self._session_started = False
                    logger.bind(tag=TAG).debug("TTS session ended")

            except queue.Empty:
                continue
            except Exception as e:
                logger.bind(tag=TAG).error(
                    f"TTS text processing failed: {str(e)}, type: {type(e).__name__}, stack: {traceback.format_exc()}"
                )

    def _submit_prefetch_async(self, text: str):
        """æäº¤å¥å­åˆ°åŽå°çº¿ç¨‹ï¼ˆéžé˜»å¡žï¼‰
        
        é¦–å¥ (segment_idx=0) ä½¿ç”¨æµå¼æ¨¡å¼ï¼Œè¾¹æŽ¥æ”¶è¾¹å‘é€
        åŽç»­å¥å­ä½¿ç”¨ç¼“å†²æ¨¡å¼ï¼Œç­‰å¾…å®ŒæˆåŽæŒ‰é¡ºåºå‘é€
        """
        segment_idx = self._segment_idx
        self._segment_idx += 1
        
        is_first_segment = (segment_idx == 0)
        
        # åˆ›å»ºé¢„åŠ è½½ç¼“å†²åŒº
        with self._prefetch_lock:
            self._prefetch_buffers[segment_idx] = {
                "text": text,
                "audio_chunks": [],
                "done": threading.Event(),
                "error": None,
                "first_chunk_time": None,
                "is_streaming": is_first_segment,  # é¦–å¥ä½¿ç”¨æµå¼æ¨¡å¼
            }
        
        if is_first_segment:
            self._first_segment_streaming = True
            self._first_segment_done.clear()
            logger.bind(tag=TAG).debug(f"ðŸš€ [Stream] Submitted first segment: {text[:30]}...")
        else:
            logger.bind(tag=TAG).debug(f"ðŸ“¦ [Prefetch] Submitted segment {segment_idx}: {text[:30]}...")
        
        # æäº¤åˆ°çº¿ç¨‹æ± 
        executor = self._get_tts_executor()
        executor.submit(self._prefetch_tts_worker, text, segment_idx)
    
    def _send_first_segment_chunks(self):
        """å‘é€é¦–å¥å·²æŽ¥æ”¶çš„éŸ³é¢‘ chunkï¼ˆéžé˜»å¡žï¼‰
        
        ä»Žé¦–å¥éŸ³é¢‘é˜Ÿåˆ—ä¸­è¯»å–å·²æŽ¥æ”¶çš„ chunk å¹¶å‘é€
        ä¸ç­‰å¾… TTS å®Œæˆï¼Œåªå‘é€å½“å‰å¯ç”¨çš„æ•°æ®
        """
        if not self._first_segment_streaming:
            return
        
        chunks_sent = 0
        while True:
            try:
                item = self._first_segment_audio_queue.get_nowait()
            except queue.Empty:
                break
            
            if item is None:
                # None è¡¨ç¤ºé¦–å¥æµå¼å¤„ç†å®Œæˆ
                self._first_segment_streaming = False
                self._first_segment_done.set()
                # æ›´æ–° _next_send_idxï¼Œå‡†å¤‡å‘é€åŽç»­å¥å­
                with self._prefetch_lock:
                    self._next_send_idx = 1
                logger.bind(tag=TAG).debug(f"âœ… [Stream] First segment streaming completed, sent {chunks_sent} chunks")
                break
            
            # å‘é€éŸ³é¢‘ chunk
            opus_data, text = item
            if chunks_sent == 0 and text:
                # é¦–ä¸ª chunk å‘é€ FIRSTï¼ˆè§¦å‘ sentence_startï¼‰
                self.tts_audio_queue.put(TTSAudioDTO(
                    sentence_type=SentenceType.FIRST,
                    audio_data=None,
                    text=text,
                    message_tag=self._message_tag,
                ))
                self._session_started = True
            
            if opus_data:
                self.tts_audio_queue.put(TTSAudioDTO(
                    sentence_type=SentenceType.MIDDLE,
                    audio_data=opus_data,
                    text=None,
                    message_tag=self._message_tag,
                ))
                chunks_sent += 1
    
    def _submit_prefetch(self, text: str):
        """æäº¤å¥å­åˆ°é¢„åŠ è½½é˜Ÿåˆ—ï¼ˆæ—§æŽ¥å£ï¼Œå…¼å®¹æ€§ä¿ç•™ï¼‰"""
        self._submit_prefetch_async(text)

    def _prefetch_tts_worker(self, text: str, segment_idx: int):
        """é¢„åŠ è½½å·¥ä½œçº¿ç¨‹ï¼šèŽ·å– TTS éŸ³é¢‘
        
        æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ç‹¬ç«‹çš„ Opus ç¼–ç å™¨å®žä¾‹ï¼Œé¿å…çº¿ç¨‹å®‰å…¨é—®é¢˜
        
        é¦–å¥ (segment_idx=0) ä½¿ç”¨æµå¼æ¨¡å¼ï¼š
        - è¾¹æŽ¥æ”¶è¾¹æ”¾å…¥ _first_segment_audio_queue
        - æ¶ˆæ¯å¤„ç†çº¿ç¨‹ä»Žé˜Ÿåˆ—è¯»å–å¹¶å‘é€ï¼Œå®žçŽ°æœ€ä½Žå»¶è¿Ÿ
        
        åŽç»­å¥å­ä½¿ç”¨ç¼“å†²æ¨¡å¼ï¼š
        - ç¼“å†²æ‰€æœ‰ chunk åˆ° audio_chunks
        - å®ŒæˆåŽæ ‡è®° doneï¼Œç­‰å¾…æŒ‰é¡ºåºå‘é€
        """
        original_text = text
        text = MarkdownCleaner.clean_markdown(text)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºé¦–å¥æµå¼æ¨¡å¼
        is_streaming = False
        with self._prefetch_lock:
            if segment_idx in self._prefetch_buffers:
                is_streaming = self._prefetch_buffers[segment_idx].get("is_streaming", False)
        
        if not text.strip():
            if is_streaming:
                # é¦–å¥ä¸ºç©ºï¼Œå‘é€ç»“æŸä¿¡å·
                self._first_segment_audio_queue.put(None)
            with self._prefetch_lock:
                if segment_idx in self._prefetch_buffers:
                    self._prefetch_buffers[segment_idx]["done"].set()
            return
        
        start_time = time.time() * 1000
        
        # åˆ›å»ºç‹¬ç«‹çš„ Opus ç¼–ç å™¨å®žä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        local_encoder = opus_encoder_utils.OpusEncoderUtils(
            sample_rate=self.sample_rate, channels=1, frame_size_ms=60
        )
        
        # è®¡ç®—æ¯å¸§å­—èŠ‚æ•°
        frame_bytes = int(
            local_encoder.sample_rate
            * local_encoder.channels
            * local_encoder.frame_size_ms
            / 1000
            * 2
        )
        
        # ä½¿ç”¨ç‹¬ç«‹çš„ PCM ç¼“å†²åŒº
        pcm_buffer = bytearray()
        audio_chunks = []  # ä»…ç”¨äºŽåŽç»­å¥å­çš„ç¼“å†²æ¨¡å¼
        
        try:
            mode_tag = "Stream" if is_streaming else "Prefetch"
            logger.bind(tag=TAG).info(f"ðŸ”„ [{mode_tag}] TTS request: segment={segment_idx}, reference_id={self.reference_id}, text={text[:50]}...")
            
            audio_stream = self._client.tts.stream(
                text=text,
                reference_id=self.reference_id,
                model=self.model,
                config=TTSConfig(
                    format=self.format,
                    sample_rate=self.sample_rate,
                    normalize=self.normalize,
                    latency=self.latency_mode,
                ),
            )
            
            first_chunk_logged = False
            first_opus_sent = False
            
            for chunk in audio_stream:
                if self.conn.client_abort:
                    logger.bind(tag=TAG).info(f"ðŸ›‘ [{mode_tag}] Abort during TTS, segment={segment_idx}")
                    break
                
                # è®°å½•é¦–åŒ…æ—¶é—´
                if not first_chunk_logged:
                    first_chunk_logged = True
                    first_chunk_time = time.time() * 1000
                    api_latency = (first_chunk_time - start_time) / 1000
                    logger.bind(tag=TAG).info(f"âš¡ [{mode_tag}] Segment {segment_idx} first chunk: {api_latency:.3f}s")
                    
                    # æ›´æ–° conn çš„é¦–åŒ…æ—¶é—´ï¼ˆç”¨äºŽå»¶è¿Ÿç»Ÿè®¡ï¼‰
                    if is_streaming:
                        self.conn.tts_first_chunk_time = first_chunk_time
                    
                    with self._prefetch_lock:
                        if segment_idx in self._prefetch_buffers:
                            self._prefetch_buffers[segment_idx]["first_chunk_time"] = first_chunk_time
                
                # ç´¯ç§¯ PCM æ•°æ®
                pcm_buffer.extend(chunk)
                
                # ç¼–ç å®Œæ•´å¸§ï¼ˆä½¿ç”¨ç‹¬ç«‹ç¼–ç å™¨ï¼‰
                while len(pcm_buffer) >= frame_bytes:
                    frame = bytes(pcm_buffer[:frame_bytes])
                    del pcm_buffer[:frame_bytes]
                    
                    opus_data = self._encode_frame_with_encoder(local_encoder, frame, False)
                    if opus_data:
                        if is_streaming:
                            # é¦–å¥æµå¼æ¨¡å¼ï¼šç›´æŽ¥æ”¾å…¥é˜Ÿåˆ—
                            # ç¬¬ä¸€ä¸ª chunk åŒæ—¶æºå¸¦æ–‡æœ¬ï¼ˆç”¨äºŽè§¦å‘ sentence_startï¼‰
                            if not first_opus_sent:
                                self._first_segment_audio_queue.put((opus_data, original_text))
                                first_opus_sent = True
                            else:
                                self._first_segment_audio_queue.put((opus_data, None))
                        else:
                            # åŽç»­å¥å­ç¼“å†²æ¨¡å¼ï¼šå­˜å…¥åˆ—è¡¨
                            audio_chunks.append(opus_data)
            
            # å¤„ç†å‰©ä½™æ•°æ®
            if pcm_buffer and not self.conn.client_abort:
                opus_data = self._encode_frame_with_encoder(local_encoder, bytes(pcm_buffer), True)
                if opus_data:
                    if is_streaming:
                        if not first_opus_sent:
                            self._first_segment_audio_queue.put((opus_data, original_text))
                        else:
                            self._first_segment_audio_queue.put((opus_data, None))
                    else:
                        audio_chunks.append(opus_data)
            
            elapsed = (time.time() * 1000 - start_time) / 1000
            logger.bind(tag=TAG).info(f"âœ… [{mode_tag}] Segment {segment_idx} completed in {elapsed:.3f}s")
            
        except Exception as e:
            logger.bind(tag=TAG).error(f"âŒ [Prefetch] Segment {segment_idx} error: {e}")
            with self._prefetch_lock:
                if segment_idx in self._prefetch_buffers:
                    self._prefetch_buffers[segment_idx]["error"] = e
        
        finally:
            # æ¸…ç†ç¼–ç å™¨
            try:
                local_encoder.close()
            except Exception:
                pass
            
            if is_streaming:
                # é¦–å¥æµå¼æ¨¡å¼ï¼šå‘é€ç»“æŸä¿¡å·
                self._first_segment_audio_queue.put(None)
            
            # å­˜å‚¨ç»“æžœå¹¶æ ‡è®°å®Œæˆ
            with self._prefetch_lock:
                if segment_idx in self._prefetch_buffers:
                    self._prefetch_buffers[segment_idx]["audio_chunks"] = audio_chunks
                    self._prefetch_buffers[segment_idx]["done"].set()

    def _encode_frame_with_encoder(self, encoder, pcm_data: bytes, end_of_stream: bool = False) -> bytes:
        """ä½¿ç”¨æŒ‡å®šç¼–ç å™¨ç¼–ç  PCM å¸§ä¸º Opus"""
        result = []
        
        def callback(opus_data):
            result.append(opus_data)
        
        encoder.encode_pcm_to_opus_stream(
            pcm_data, end_of_stream=end_of_stream, callback=callback
        )
        
        return result[0] if result else None

    def _flush_completed_prefetch(self):
        """å‘é€å·²å®Œæˆçš„é¢„åŠ è½½ç»“æžœï¼ˆæŒ‰é¡ºåºï¼‰
        
        æ³¨æ„ï¼šé¦–å¥ (segment 0) é€šè¿‡æµå¼é˜Ÿåˆ—å¤„ç†ï¼Œè¿™é‡Œåªå¤„ç† segment >= 1
        å¿…é¡»ç­‰å¾…é¦–å¥æµå¼å®ŒæˆåŽæ‰å¼€å§‹å¤„ç†åŽç»­å¥å­
        """
        # é¦–å¥å°šæœªå®Œæˆï¼Œä¸å¤„ç†åŽç»­å¥å­
        if self._first_segment_streaming:
            return
        
        while True:
            with self._prefetch_lock:
                # æ£€æŸ¥ä¸‹ä¸€ä¸ªè¦å‘é€çš„æ®µè½æ˜¯å¦å°±ç»ªï¼ˆä»Ž segment 1 å¼€å§‹ï¼‰
                if self._next_send_idx not in self._prefetch_buffers:
                    break
                
                buffer = self._prefetch_buffers[self._next_send_idx]
                
                # è·³è¿‡é¦–å¥ï¼ˆå·²é€šè¿‡æµå¼é˜Ÿåˆ—å¤„ç†ï¼‰
                if buffer.get("is_streaming", False):
                    segment_idx = self._next_send_idx
                    self._next_send_idx += 1
                    del self._prefetch_buffers[segment_idx]
                    continue
                
                # å¦‚æžœè¿˜æ²¡å®Œæˆï¼Œç­‰å¾…
                if not buffer["done"].is_set():
                    break
                
                # å–å‡ºå¹¶åˆ é™¤ç¼“å†²åŒº
                segment_idx = self._next_send_idx
                self._next_send_idx += 1
                del self._prefetch_buffers[segment_idx]
            
            # å‘é€ç»“æžœï¼ˆåœ¨é”å¤–æ“ä½œï¼‰
            self._send_prefetch_result(buffer)

    def _flush_all_prefetch(self):
        """ç­‰å¾…å¹¶å‘é€æ‰€æœ‰å‰©ä½™çš„é¢„åŠ è½½ç»“æžœ
        
        åœ¨ä¼šè¯ç»“æŸæ—¶è°ƒç”¨ï¼Œç¡®ä¿æ‰€æœ‰éŸ³é¢‘éƒ½å‘é€å®Œæ¯•
        """
        # é¦–å…ˆç­‰å¾…é¦–å¥æµå¼å®Œæˆï¼ˆå¦‚æžœè¿˜åœ¨è¿›è¡Œä¸­ï¼‰
        if self._first_segment_streaming:
            logger.bind(tag=TAG).debug("Waiting for first segment streaming to complete...")
            self._first_segment_done.wait(timeout=30)
            # å‘é€é¦–å¥é˜Ÿåˆ—ä¸­å‰©ä½™çš„ chunk
            self._send_first_segment_chunks()
        
        while True:
            with self._prefetch_lock:
                if self._next_send_idx not in self._prefetch_buffers:
                    break
                
                buffer = self._prefetch_buffers[self._next_send_idx]
            
            # è·³è¿‡é¦–å¥ï¼ˆå·²é€šè¿‡æµå¼é˜Ÿåˆ—å¤„ç†ï¼‰
            if buffer.get("is_streaming", False):
                with self._prefetch_lock:
                    segment_idx = self._next_send_idx
                    self._next_send_idx += 1
                    if segment_idx in self._prefetch_buffers:
                        del self._prefetch_buffers[segment_idx]
                continue
            
            # ç­‰å¾…å®Œæˆ
            buffer["done"].wait(timeout=30)
            
            with self._prefetch_lock:
                if self._next_send_idx in self._prefetch_buffers:
                    segment_idx = self._next_send_idx
                    self._next_send_idx += 1
                    del self._prefetch_buffers[segment_idx]
            
            # å‘é€ç»“æžœ
            self._send_prefetch_result(buffer)

    def _send_prefetch_result(self, buffer: dict):
        """å‘é€é¢„åŠ è½½ç»“æžœåˆ°éŸ³é¢‘é˜Ÿåˆ—"""
        text = buffer["text"]
        audio_chunks = buffer["audio_chunks"]
        error = buffer["error"]
        
        if error:
            logger.bind(tag=TAG).warning(f"Skipping segment due to prefetch error: {error}")
            return
        
        if not audio_chunks:
            logger.bind(tag=TAG).debug(f"Skipping empty segment: {text[:30]}...")
            return
        
        # å‘é€ FIRSTï¼ˆè§¦å‘ sentence_startï¼‰
        self.tts_audio_queue.put(TTSAudioDTO(
            sentence_type=SentenceType.FIRST,
            audio_data=None,
            text=text,
            message_tag=self._message_tag,
        ))
        self._session_started = True
        
        # å‘é€æ‰€æœ‰éŸ³é¢‘å—
        for opus_data in audio_chunks:
            if self.conn.client_abort:
                break
            self.tts_audio_queue.put(TTSAudioDTO(
                sentence_type=SentenceType.MIDDLE,
                audio_data=opus_data,
                text=None,
                message_tag=self._message_tag,
            ))
        
        logger.bind(tag=TAG).debug(f"ðŸ“¤ [Prefetch] Sent segment: {text[:30]}... ({len(audio_chunks)} chunks)")

    def _stream_tts_segment(self, text: str):
        """[DEPRECATED] åŒæ­¥é˜»å¡žå¼ TTS streaming.
        
        æ­¤æ–¹æ³•å·²è¢« _prefetch_tts_worker + _first_segment_audio_queue æœºåˆ¶å–ä»£ã€‚
        ä¿ç•™æ­¤ä»£ç ç”¨äºŽå‚è€ƒå’Œå›žæ»šã€‚
        
        é—®é¢˜ï¼šæ­¤æ–¹æ³•ä¼šé˜»å¡žæ¶ˆæ¯å¤„ç†çº¿ç¨‹ï¼Œå¯¼è‡´åŽç»­å¥å­æ— æ³•å¹¶è¡Œ prefetchã€‚
        """
        text = MarkdownCleaner.clean_markdown(text)
        if not text.strip():
            return
        
        logger.bind(tag=TAG).info(f"FishSpeech streaming (first segment): {text}")
        start_time = time.time() * 1000
        first_chunk_logged = False  # Track first chunk for this segment
        
        # Calculate bytes per frame for Opus encoding
        frame_bytes = int(
            self.opus_encoder.sample_rate
            * self.opus_encoder.channels
            * self.opus_encoder.frame_size_ms
            / 1000
            * 2  # 16-bit = 2 bytes per sample
        )
        
        try:
            # Get audio stream from FishSpeech
            logger.bind(tag=TAG).info(f"TTS stream request: reference_id={self.reference_id}, text={text[:50]}...")
            audio_stream = self._client.tts.stream(
                text=text,
                reference_id=self.reference_id,
                model=self.model,
                config=TTSConfig(
                    format=self.format,
                    sample_rate=self.sample_rate,
                    normalize=self.normalize,
                    latency=self.latency_mode,
                ),
            )
            
            # Send FIRST for each text segment (triggers sentence_start on client)
            # This ensures client receives all text segments, not just the first one
            self.tts_audio_queue.put(TTSAudioDTO(
                sentence_type=SentenceType.FIRST,
                audio_data=None,
                text=text,
                message_tag=self._message_tag,
            ))
            self._session_started = True
            
            # Process audio stream chunks
            for chunk in audio_stream:
                # Check for abort during streaming
                if self.conn.client_abort:
                    logger.bind(tag=TAG).info("Abort during TTS streaming, stopping")
                    break
                
                # Log first chunk latency for each segment
                if not first_chunk_logged:
                    first_chunk_logged = True
                    first_chunk_time = time.time() * 1000
                    self.conn.tts_first_chunk_time = first_chunk_time
                    api_latency = (first_chunk_time - start_time) / 1000
                    logger.bind(tag=TAG).info(f"[Latency] TTS segment first chunk: {api_latency:.3f}s")
                
                # Add chunk to PCM buffer
                self.pcm_buffer.extend(chunk)
                
                # Encode and send complete frames as MIDDLE messages
                while len(self.pcm_buffer) >= frame_bytes:
                    # Check abort again before processing
                    if self.conn.client_abort:
                        break
                    
                    frame = bytes(self.pcm_buffer[:frame_bytes])
                    del self.pcm_buffer[:frame_bytes]
                    
                    self.opus_encoder.encode_pcm_to_opus_stream(
                        frame, end_of_stream=False, callback=self._handle_opus_middle
                    )
            
            # Flush remaining data (less than one frame)
            if self.pcm_buffer and not self.conn.client_abort:
                self.opus_encoder.encode_pcm_to_opus_stream(
                    bytes(self.pcm_buffer),
                    end_of_stream=True,
                    callback=self._handle_opus_middle,
                )
                self.pcm_buffer.clear()
            
            elapsed = (time.time() * 1000 - start_time) / 1000
            logger.bind(tag=TAG).debug(f"TTS segment completed in {elapsed:.3f}s: {text[:30]}...")
            
        except Exception as e:
            logger.bind(tag=TAG).error(f"FishSpeech streaming error: {e}")
            # On error, clear buffer to avoid corrupted audio
            self.pcm_buffer.clear()

    def _handle_opus_middle(self, opus_data: bytes):
        """Handle encoded Opus data, send as MIDDLE message"""
        if self.conn.client_abort:
            return
        
        self.tts_audio_queue.put(TTSAudioDTO(
            sentence_type=SentenceType.MIDDLE,
            audio_data=opus_data,
            text=None,
            message_tag=self._message_tag,
        ))

    def _extract_segment(self) -> str | None:
        """Extract next text segment based on punctuation.
        
        Returns cleaned segment text or None if no complete segment found.
        """
        current_text = self._text_buffer[self._processed_idx:]
        if not current_text:
            return None
        
        is_first_segment = not self._session_started

        # Choose max length cap (prevent extremely long segments without punctuation)
        max_chars = (
            getattr(self, "first_segment_max_chars", 0)
            if is_first_segment
            else getattr(self, "segment_max_chars", 0)
        )
        if max_chars is None:
            max_chars = 0
        if max_chars < 0:
            max_chars = 0

        # Helper: find first dot that isn't a decimal point or part of ellipsis (supports '.' and 'ï¼Ž')
        def _find_first_non_decimal_dot(text: str, dot_char: str, start_pos: int) -> int:
            pos = max(start_pos, 0)
            while True:
                pos = text.find(dot_char, pos)
                if pos == -1:
                    return -1
                prev_ch = text[pos - 1] if pos - 1 >= 0 else ""
                next_ch = text[pos + 1] if pos + 1 < len(text) else ""
                # Skip decimal points (e.g., "1.5")
                if prev_ch.isdigit() and next_ch.isdigit():
                    pos += 1
                    continue
                # Skip ellipsis: if next char is also a dot, skip this one
                # This handles "..." or "...." patterns
                if next_ch == dot_char:
                    pos += 1
                    continue
                # Skip if this dot follows another dot (part of ellipsis)
                if prev_ch == dot_char:
                    pos += 1
                    continue
                return pos

        def _find_first_punct(text: str, puncts: tuple[str, ...], start_pos: int) -> int:
            earliest = -1
            for punct in puncts:
                if punct in (".", "ï¼Ž"):
                    pos = _find_first_non_decimal_dot(text, punct, start_pos)
                else:
                    pos = text.find(punct, start_pos)
                if pos != -1 and (earliest == -1 or pos < earliest):
                    earliest = pos
            return earliest

        # 1) Always try hard puncts (sentence boundaries)
        hard_pos = _find_first_punct(current_text, self.HARD_PUNCTS, 0)

        # 2) Optionally allow soft puncts (commas/colons/newlines) for lower latency
        soft_pos = -1
        if is_first_segment:
            # First segment: always allow soft puncts (min chars configurable; default 0 to allow "Oh,")
            min_chars = max(int(getattr(self, "first_soft_punct_min_chars", 0)), 0)
            soft_pos = _find_first_punct(current_text, self.SOFT_PUNCTS, max(min_chars - 1, 0))
        elif getattr(self, "enable_soft_puncts", True):
            min_chars = max(int(getattr(self, "soft_punct_min_chars", 0)), 0)
            soft_pos = _find_first_punct(current_text, self.SOFT_PUNCTS, max(min_chars - 1, 0))

        # Pick the earliest boundary we can use
        split_pos = -1
        if hard_pos != -1 and (soft_pos == -1 or hard_pos <= soft_pos):
            split_pos = hard_pos
        elif soft_pos != -1:
            split_pos = soft_pos

        if split_pos != -1:
            segment_raw = current_text[: split_pos + 1]
            self._processed_idx += len(segment_raw)
            return textUtils.get_string_no_punctuation_or_emoji(segment_raw)

        # 3) Fallback: no punctuation found, but segment is too long â†’ force cut to avoid TTS latency spikes
        if max_chars > 0 and len(current_text) >= max_chars:
            # Prefer cutting at whitespace before max_chars
            window = current_text[:max_chars]
            cut_at = window.rfind(" ")
            if cut_at <= 0:
                # No whitespace (e.g., Chinese) â†’ cut hard at max_chars
                cut_at = max_chars

            # Consume the cut segment plus subsequent whitespace (so next segment doesn't start with spaces)
            consume_len = cut_at
            while consume_len < len(current_text) and current_text[consume_len].isspace():
                consume_len += 1

            segment_raw = current_text[:cut_at]
            self._processed_idx += consume_len
            return textUtils.get_string_no_punctuation_or_emoji(segment_raw)

        return None

    def _audio_play_priority_thread(self):
        """Override base class to accumulate all segments into one report.
        
        - Each FIRST still triggers sentence_start on client (for real-time display)
        - But report accumulates all text segments and audio, only reports on LAST
        """
        from core.utils.output_counter import add_device_output
        from core.handle.reportHandle import enqueue_tts_report
        from core.handle.sendAudioHandle import sendAudioMessage
        from core.utils.opus import pack_opus_with_header
        
        # Accumulated text and audio for the entire session (one LLM response)
        session_text_parts = []
        session_audio = []
        session_message_tag = MessageTag.NORMAL
        
        # Track last send future for ordering
        last_send_future = None
        
        while not self.conn.stop_event.is_set():
            text = None
            try:
                try:
                    tts_audio_message = self.tts_audio_queue.get(timeout=0.1)
                    if isinstance(tts_audio_message, TTSAudioDTO):
                        sentence_type = tts_audio_message.sentence_type
                        audio_datas = tts_audio_message.audio_data
                        text = tts_audio_message.text
                        message_tag = tts_audio_message.message_tag
                    elif isinstance(tts_audio_message, tuple):
                        sentence_type = tts_audio_message[0]
                        audio_datas = tts_audio_message[1]
                        text = tts_audio_message[2]
                        message_tag = MessageTag.NORMAL
                    else:
                        logger.bind(tag=TAG).warning(f"Unknown tts_audio_message type: {type(tts_audio_message)}")
                        continue
                except queue.Empty:
                    if self.conn.stop_event.is_set():
                        break
                    continue

                if self.conn.client_abort:
                    # Only handle abort once per session
                    if session_text_parts or session_audio:
                        logger.bind(tag=TAG).debug("Received abort, reporting accumulated content")
                        full_text = "".join(session_text_parts)
                        if full_text and session_audio:
                            enqueue_tts_report(self.conn, full_text, session_audio, session_message_tag)
                            logger.bind(tag=TAG).info(f"Abort report: {full_text[:50]}...")
                        
                        # æ¸…ç©ºé˜Ÿåˆ—ä¸­çš„æ‰€æœ‰å¾…å¤„ç†æ¶ˆæ¯ï¼Œé¿å… stop åŽç»§ç»­å‘é€
                        # æ³¨æ„ï¼šè¿™ä¸ä¼šä¸¢å¤±æ­£å¸¸æ•°æ®ï¼Œå› ä¸ºï¼š
                        # 1. client_abort=True åªåœ¨ç”¨æˆ·ä¸»åŠ¨æ‰“æ–­æ—¶è®¾ç½®
                        # 2. è¢«æ¸…ç©ºçš„éŸ³é¢‘å±žäºŽè¢«æ‰“æ–­çš„ä¼šè¯ï¼Œç”¨æˆ·å·²ä¸éœ€è¦
                        # 3. æ–°ä¼šè¯å¼€å§‹æ—¶ client_abort ä¼šè¢«é‡ç½®ä¸º False
                        while not self.tts_audio_queue.empty():
                            try:
                                self.tts_audio_queue.get_nowait()
                            except queue.Empty:
                                break
                        
                        # Send LAST to trigger TTS stop message
                        last_send_future = asyncio.run_coroutine_threadsafe(
                            sendAudioMessage(self.conn, SentenceType.LAST, None, None, session_message_tag),
                            self.conn.loop,
                        )
                        session_text_parts, session_audio = [], []
                    continue

                # Handle FIRST: accumulate text, don't report yet
                if sentence_type == SentenceType.FIRST:
                    if text:
                        session_text_parts.append(text)
                    session_message_tag = message_tag

                # Handle MIDDLE: accumulate audio
                if isinstance(audio_datas, bytes):
                    audio_with_header = pack_opus_with_header(audio_datas, message_tag)
                    session_audio.append(audio_with_header)

                # Handle LAST: report the entire accumulated session
                if sentence_type == SentenceType.LAST:
                    if session_text_parts or session_audio:
                        full_text = "".join(session_text_parts)
                        if full_text and session_audio:
                            enqueue_tts_report(self.conn, full_text, session_audio, session_message_tag)
                            logger.bind(tag=TAG).info(f"Session report: {full_text[:80]}...")
                    session_text_parts, session_audio = [], []

                # Wait for previous send to complete (maintain order)
                if last_send_future is not None:
                    try:
                        last_send_future.result(timeout=5.0)
                    except Exception as e:
                        logger.bind(tag=TAG).warning(f"Previous audio send timeout: {e}")

                # Send audio to client (async, non-blocking)
                last_send_future = asyncio.run_coroutine_threadsafe(
                    sendAudioMessage(self.conn, sentence_type, audio_datas, text, message_tag),
                    self.conn.loop,
                )

                # Track output
                if self.conn.max_output_size > 0 and text:
                    add_device_output(self.conn.headers.get("device-id"), len(text))

            except Exception as e:
                logger.bind(tag=TAG).error(f"_audio_play_priority_thread error: {text} {e}")

        # Wait for last send to complete before exiting
        if last_send_future is not None:
            try:
                last_send_future.result(timeout=2.0)
            except Exception as e:
                logger.bind(tag=TAG).debug(f"Final audio send failed (connection may be closed): {e}")
        
        # On connection close, report remaining accumulated data
        if session_text_parts and session_audio:
            try:
                full_text = "".join(session_text_parts)
                enqueue_tts_report(self.conn, full_text, session_audio, session_message_tag)
                logger.bind(tag=TAG).info(f"Connection close report: {full_text}")
            except Exception as e:
                logger.bind(tag=TAG).warning(f"Connection close report failed: {e}")

    async def text_to_speak(self, text, output_file):
        """Non-streaming TTS interface (required by base class)
        
        This provider primarily uses streaming, but this method is needed
        for compatibility with base class abstract method.
        """
        text = MarkdownCleaner.clean_markdown(text)
        audio_bytes = self._client.tts.convert(
            text=text,
            reference_id=self.reference_id,
            model=self.model,
            config=TTSConfig(
                format=self.format,
                sample_rate=self.sample_rate,
                normalize=self.normalize,
                latency=self.latency_mode,
            )
        )
        if output_file:
            with open(output_file, 'wb') as f:
                f.write(audio_bytes)
        return audio_bytes

    async def close(self):
        """Resource cleanup"""
        await super().close()
        if hasattr(self, "opus_encoder"):
            self.opus_encoder.close()
        if hasattr(self, "_client"):
            self._client.close()
        if hasattr(self, "_httpx_client"):
            self._httpx_client.close()
        if hasattr(self, "_tts_executor") and self._tts_executor:
            self._tts_executor.shutdown(wait=False)
